# RoboMasterGym

RoboMaster IsaacGym Framework

> 本项目目前只是调试完成部分项目与IsaacGym的相关接口、资产配置和规则设置，暂时并没有引入强化学习框架和相关算法（后续考虑引入LeggedGym等框架）
## TODO

- [x] 自瞄小陀螺
- [x] 工程自动兑矿
- [ ] 自动打符
- [ ] 轮腿训练
- [ ] 哨兵导航
- [ ] 战术推演


## AutoAim
| 静态截图 | 内录第一视角 |
|----------|--------------|
| <img src="doc/autoaim.png" width="350"> | <img src="doc/autoaim_1st.gif" width="350"> |
| <img src="doc/autoaim_test.gif" width="350"> | <img src="doc/autoaim_multi.gif" width="350"> |

## Exchange
| 内录第一视角 | 第三方视角 |
|----------|------------|
| <img src="doc/exchange.png" width="350"> | <img src="doc/exchange_3rd.gif" width="350"> |
| <img src="doc/exchange_base.gif" width="350"> | <img src="doc/exchange_multi.gif" width="350"> |

## 待补充

## URDF压缩

从SW导出URDF时，对于相对复杂的机器人导出STL模型面数过多，导致模型体积过大IsaacGym加载缓慢或失败，所以本项目采用Open3D对URDF meshes进行批量压缩，可大大优化模型体积与导入速度

```
python simplify_stl.py <输入目录> <输出目录> <压缩率(0.0~1.0)>
```

## 说明
很显然如果使用纯视觉作为强化学习输入，要想达到端到端控制，实用价值并不高，因为虚拟环境中图像采集与现实差距很大，当然笔者也在思考如何设计模型输入能够让机器人去完成更高精度、高实时性的任务，也许可以结合传统控制和视觉神经网络识别去做一个中间层以便更好的完成任务。RoboMaster比赛为我们提供了一个复杂而又令人向往的机器人世界，也许在我们有限的参赛时间里无法真正实现本项目所设想的目标，但是本项目可以让你在虚拟的乌托邦世界过一把瘾，并期待着有一天能够迁移到实物中去。

由于笔者在参赛期间深受王工端到端强化学习的震撼，以及在24、25年机器人产业快速发展和曝光使得“机器人训练场”进入到大众视野，这是一种很神奇的感受，当然作为本科生眼界有限，但是你想想昨天你还在一个没多少人听说过的领域试探，第二天这玩意的神奇被大众熟知，有种押中未来的感觉，哈哈。但是由于本人水平、时间有限并为在本科期间作出突出的工作，深感惭愧。

当然，在前辈们看来强化学习并不算什么新鲜东西，在我心中奉为圭臬的神经网络控制，早在10几年前就是研究生们用来水论文的工具了。所以在本项目开发期间也在思考未来的机器人控制的风口在哪，可能是和传统控制的结合、或者和多模态大模型的结合、或者像稚晖君的机器人世界模型，都有可能。

若干年前RoboMaster硕哥就探讨过传统控制和强化学习的未来，那时强化学习在机器人上的应用还微乎其微，虽然他偏向于传统控制，但是也为强化学习搭建了一个平台，就是RoboMaster AI挑战赛，虽然现在演变成无人机了，但是其前瞻性的想法是令人称赞的。

[未来的机器人未来 ——YY硕](https://zhuanlan.zhihu.com/p/27235639)

[RoboMaster AI 挑战赛科研思路浅谈 ——YY硕](https://zhuanlan.zhihu.com/p/33110675)

怀揣这机器人工程师的理想与信念，我们幻想总有一套法则能够在机器人电机线圈间传递电子驱动关节，用一串数据去感受、理解世界，我们以造物主的身份为其编写下每一行基因密码，让其在更大的自然中不断进化。

## 开源引用
>[RM2024-工程机器人机械结构开源上海交通大学-云汉交龙战队](https://bbs.robomaster.com/article/54080?source=4)